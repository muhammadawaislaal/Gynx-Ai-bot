I'll reconstruct the README from the screenshot content in a clean, properly formatted way:

```markdown
<div align="center">

# Gynx Ai Chat Interface

![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![LangChain](https://img.shields.io/badge/langChain-0.1+-orange.svg)
![Groq](https://img.shields.io/badge/Groq_API-purple.svg)
![Version](https://img.shields.io/badge/Version-1.0.0-green.svg)

**Advanced AI Assistant with Conversation Memory | Context-Aware Responses | Multi-Model Support**

[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://gynx-ai.streamlit.app)
[![Report Bug](https://img.shields.io/badge/%F0%9F%90%9B-Report_Bug-red)](https://github.com/muhammadawaislaal/gynx-ai/issues)
[![Feature Request](https://img.shields.io/badge/%F0%9F%92%A1-Feature_Request-blue)](https://github.com/muhammadawaislaal/gynx-ai/issues)

</div>

## ğŸ“‹ Table of Contents
- [âœ¨ Features](#features)
- [ğŸš€ Quick Start](#quick-start)
- [ğŸ› ï¸ Installation](#installation)
- [âš™ï¸ Configuration](#configuration)
- [ğŸ’¬ Usage Guide](#usage-guide)
- [ğŸ—ï¸ Architecture](#architecture)
- [ğŸ”§ API Reference](#api-reference)
- [ğŸ¨ UI Components](#ui-components)
- [ğŸ”’ Security](#security)
- [ğŸ¤ Contributing](#contributing)
- [ğŸ“„ License](#license)
- [ğŸ‘¨â€ğŸ’» Developer](#developer)

## âœ¨ Features

### ğŸ¯ Core Features
- **ğŸ¤– Multi-Model AI Support** - Access to 7+ cutting-edge LLMs via Groq API
- **ğŸ’¬ Intelligent Conversation Memory** - Maintains context across 6+ previous messages
- **âš¡ Real-time Streaming Responses** - Dynamic text streaming with typing effect
- **ğŸ“± Session Management** - Create, switch, and manage multiple chat sessions
- **ğŸ¨ Beautiful Chat Interface** - Modern, responsive UI with custom CSS styling

### ğŸ›¡ï¸ Professional Features
- **ğŸ”§ Adjustable Parameters** - Fine-tune creativity, response length, and model selection
- **ğŸ“Š Conversation History** - Persistent chat sessions with timestamps
- **âš™ï¸ Advanced Model Settings** - Temperature, max tokens, top-p, frequency penalty
- **ğŸ”„ Dynamic Session Switching** - Seamlessly switch between different conversations

### ğŸš€ Technical Highlights
- LangChain integration for robust conversation chains
- Streamlit secrets management for secure API keys
- UUID-based session tracking
- Real-time logging and error handling
- Responsive design with custom CSS

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Groq API Key (get from [Groq Console](https://console.groq.com))
- Streamlit account (for deployment)

### One-Line Installation
```bash
pip install streamlit langchain-groq python-dotenv && streamlit run app.py
```

## ğŸ› ï¸ Installation

### Method 1: Local Installation
```bash
# Clone the repository
git clone https://github.com/muhammadawaislaal/gynx-ai.git
cd gynx-ai

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install streamlit langchain-groq python-dotenv uuid

# Run the application
streamlit run app.py
```

### Method 2: Docker Installation
```bash
# Build Docker image
docker build -t gynx-ai .

# Run container
docker run -p 8501:8501 gynx-ai
```

## âš™ï¸ Configuration

### Environment Setup
Create a `.env` file for local development:
```env
GROQ_API_KEY=your_groq_api_key_here
```

### Streamlit Secrets (Cloud Deployment)
For Streamlit Cloud, create `.streamlit/secrets.toml`:
```toml
GROQ_API_KEY = "your_groq_api_key_here"
```

### Available AI Models
```python
AVAILABLE_MODELS = [
    "llama-3.1-8b-instant",
    "llama-3.3-70b-versatile",
    "llama-3.2-3b-preview",
    "llama-3.2-1b-preview",
    "llama-3.2-90b-text-preview",
    "mixtral-8x7b-32768",
    "gemma2-9b-it"
]
```

## ğŸ’¬ Usage Guide

### 1. Starting a New Chat
1. Click "â• New Chat" in the sidebar
2. Type your message in the chat input
3. Watch as the AI streams responses in real-time

### 2. Managing Sessions
- **Switch Chats**: Use dropdown in sidebar
- **View History**: All messages display with timestamps
- **Track Conversations**: Each session shows message count

### 3. Customizing AI Behavior
- **Select Model**: Choose from 7 available LLMs
- **Adjust Creativity**: Slider from 0.0 (precise) to 1.0 (creative)
- **Control Length**: Set maximum response tokens (100-4000)
- **Apply Settings**: Changes take effect immediately

## ğŸ—ï¸ Architecture

### System Design
```mermaid
graph TB
    A[User Interface] --> B[Streamlit Frontend]
    B --> C[Session Manager]
    C --> D[Chat Storage]
    B --> E[LangChain Integration]
    E --> F[Groq API]
    F --> G[AI Models]
    G --> H[Response Streaming]
    H --> A
```

### Key Components
- **Frontend**: Streamlit with custom CSS
- **Backend**: Python, LangChain, Groq API
- **Storage**: Session state with UUID tracking
- **Processing**: Real-time text streaming

## ğŸ”§ API Reference

### Core Functions
```python
def initialize_llm(model_name, temperature, max_tokens):
    """Initialize LangChain Groq LLM with parameters"""
    pass

def setup_conversation_chain():
    """Setup conversation chain with memory context"""
    pass
```

### Session Structure
```python
{
    "chat_sessions": {
        "session_id": [
            {"role": "user/assistant", "content": "message", "timestamp": 123}
        ]
    },
    "current_chat_id": "active_session",
    "conversation": "LangChain runnable"
}
```

## ğŸ¨ UI Components

### Sidebar Features
- **Model Configuration Panel**
- **Chat Sessions Manager**
- **Developer Information Card**

### Chat Interface
- **Message Bubbles**: Different styling for user/assistant
- **Timestamps**: Each message shows time
- **Avatar Icons**: Visual indicators (ğŸ‘¤/ğŸ¤–)
- **Streaming Animation**: Real-time typing effect

## ğŸ”’ Security

### Data Protection
- **Local Processing**: Conversations stored in session memory only
- **No Persistent Storage**: Data cleared on browser refresh
- **Secure API Calls**: Encrypted HTTPS connections
- **API Key Protection**: Stored in Streamlit secrets

### Privacy Features
- **No User Data Collection**
- **Session Isolation**
- **Temporary Storage**
- **No Cookies**

## ğŸ¤ Contributing

### How to Contribute
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

### Contribution Areas
- ğŸ› Bug fixes
- âœ¨ New features
- ğŸ¨ UI improvements
- ğŸ“š Documentation
- âš¡ Performance

## ğŸ“„ License

MIT License - See LICENSE file for details.

## ğŸ‘¨â€ğŸ’» Developer

**Muhammad Awais Laal**
- Generative AI Developer
- GitHub: [@muhammadawaislaal](https://github.com/muhammadawaislaal)
- Email: m.awaislaal@gmail.com

<div align="center">

---

â­ **If you find this project useful, please give it a star on GitHub!**

**Built with â¤ï¸ by Muhammad Awais Laal**

</div>
```

